{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv', usecols=['id', 'genome_sequence', \"species\"]) # Removes the index column of the csv\n",
    "print(\"Shape of the dataset: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that there are no missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the balancing of the target\n",
    "df.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average length of the genome sequences\n",
    "df.genome_sequence.apply(lambda x: len(x)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the few that aren't of the 80 long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the <20 genome sequences that are not 80 long\n",
    "df = df[df.genome_sequence.apply(lambda x: len(x)) == 80]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label column that change the species name into a number\n",
    "labels_dict = {species: i for i, species in enumerate(df.species.unique())}\n",
    "df['label'] = df.species.map(labels_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to one hot encode a DNA sequence\n",
    "def one_hot_encote_dna(seq):\n",
    "    return np.array(\n",
    "        [\n",
    "            [\n",
    "                1 if c == \"A\" else 0,\n",
    "                1 if c == \"C\" else 0,\n",
    "                1 if c == \"G\" else 0,\n",
    "                1 if c == \"T\" else 0,\n",
    "            ]\n",
    "            for c in seq.upper()\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=['id', 'species'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=random_state)\n",
    "print(\"Shape of the train dataset: \", df_train.shape)\n",
    "print(\"Shape of the test dataset: \", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset for CNN\n",
    "class GenomeDatasetCNN(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ]) if transform is None else transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        label = row.label\n",
    "        dna = row.genome_sequence\n",
    "        dna = one_hot_encote_dna(dna)\n",
    "        dna = torch.from_numpy(dna)\n",
    "        dna = torch.reshape(dna, (dna.shape[1], dna.shape[0]))\n",
    "        # convert all to float\n",
    "        dna = dna.float()\n",
    "        label = torch.tensor(label).float()\n",
    "        return dna, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_one_hot_encoded_dna(genome_seq):\n",
    "    # Plot the one hot encoded DNA sequence\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    plt.imshow(genome_seq, cmap=\"hot\")\n",
    "    plt.xticks(range(0, genome_seq.shape[0]))\n",
    "    plt.yticks(range(0, 4), [\"A\", \"C\", \"G\", \"T\"])\n",
    "    plt.show()\n",
    "\n",
    "test_print = one_hot_encote_dna(df_train.iloc[0].genome_sequence).transpose(1, 0)\n",
    "print_one_hot_encoded_dna(test_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GenomeDatasetCNN(df_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32)\n",
    "\n",
    "# print an example of the dataset\n",
    "dna, label = next(iter(dataloader))\n",
    "print(\"DNA shape: \", dna.shape)\n",
    "print(\"Label shape: \", label.shape)\n",
    "print(\"Label: \", label)\n",
    "print(\"DNA: \", dna[0])\n",
    "print_one_hot_encoded_dna(dna[0]) # Print the first DNA sequence of the batch\n",
    "\n",
    "# Make our test and train datasets and data loaders\n",
    "train_dataset = GenomeDatasetCNN(df_train)\n",
    "test_dataset = GenomeDatasetCNN(df_test)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1024, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the model\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        \"\"\"\n",
    "        # In channel: 4\n",
    "        # Use 3 layers of Conv1D with kernel size (2, 3, 3) and stride (0, 1, 1), and padding (0, 1, 1)\n",
    "        The in channels are: (4, 16, 32)\n",
    "        The out channels are: (16, 32, 64)\n",
    "        # Use 1 layer of MaxPool1D with kernel size (2) and stride (2)\n",
    "        # Use 2 layers of Linear with 128 and 64 neurons\n",
    "        # Use 1 layer of Linear with 1 neuron\n",
    "        \"\"\"\n",
    "\n",
    "        self.conv1 = nn.Conv1d(4, 16, 2, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv1d(16, 32, 3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(32, 64, 3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.fc1 = nn.Linear(19*64, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "def train_model(model, optimizer, criterion, dataloader, epochs=10, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        train_loss = 0\n",
    "        for batch_idx, (genome_seq, label) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "            optimizer.zero_grad()\n",
    "            genome_seq = genome_seq.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(genome_seq)\n",
    "            loss = criterion(output.view(-1), label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        print(\"Train loss: \", train_loss / len(dataloader))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(model, optimizer, criterion, train_dataloader, epochs=3, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy on the test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for batch_idx, (genome_seq, label) in enumerate(dataloader):\n",
    "        output = model(genome_seq)\n",
    "        y_true.extend(label.numpy())\n",
    "        y_pred.extend(output.argmax(axis=1).numpy())\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(\"Accuracy on the test set: \", compute_accuracy(model, test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
