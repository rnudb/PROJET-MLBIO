{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset:  (19800000, 3)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/train.csv\", usecols=[\"id\", \"genome_sequence\", \"species\"]\n",
    ")  # Removes the index column of the csv\n",
    "print(\"Shape of the dataset: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>genome_sequence</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11408003</td>\n",
       "      <td>ccacatcccctccagcacctgttgtttcctgactttttaatgattg...</td>\n",
       "      <td>Gorilla_gorilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18639873</td>\n",
       "      <td>tgtttacttgccaatctttgtttagctgtcagagtggcttgctaaa...</td>\n",
       "      <td>Gorilla_gorilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9869298</td>\n",
       "      <td>tctgtgaagaaagacattggtagcttgatggggatgacattgaatc...</td>\n",
       "      <td>Homo_sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10762804</td>\n",
       "      <td>ttgtgagaattacgtgagatgatagatttagggactatagaatagt...</td>\n",
       "      <td>Gorilla_gorilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13724428</td>\n",
       "      <td>gcaaaaaataagttgataagttgattgatatgttattagcttaatt...</td>\n",
       "      <td>Gorilla_gorilla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                    genome_sequence  \\\n",
       "0  11408003  ccacatcccctccagcacctgttgtttcctgactttttaatgattg...   \n",
       "1  18639873  tgtttacttgccaatctttgtttagctgtcagagtggcttgctaaa...   \n",
       "2   9869298  tctgtgaagaaagacattggtagcttgatggggatgacattgaatc...   \n",
       "3  10762804  ttgtgagaattacgtgagatgatagatttagggactatagaatagt...   \n",
       "4  13724428  gcaaaaaataagttgataagttgattgatatgttattagcttaatt...   \n",
       "\n",
       "           species  \n",
       "0  Gorilla_gorilla  \n",
       "1  Gorilla_gorilla  \n",
       "2     Homo_sapiens  \n",
       "3  Gorilla_gorilla  \n",
       "4  Gorilla_gorilla  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 0\n",
       "genome_sequence    0\n",
       "species            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that there are no missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species\n",
       "Homo_sapiens       9900585\n",
       "Gorilla_gorilla    9899415\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balancing of the target\n",
    "df.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genome_sequence\n",
       "80    19799984\n",
       "37           2\n",
       "39           1\n",
       "2            1\n",
       "30           1\n",
       "25           1\n",
       "16           1\n",
       "3            1\n",
       "15           1\n",
       "57           1\n",
       "48           1\n",
       "32           1\n",
       "31           1\n",
       "43           1\n",
       "60           1\n",
       "50           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the average length of the genome sequences\n",
    "df.genome_sequence.apply(lambda x: len(x)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the few that aren't of the 80 long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19799984, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the <20 genome sequences that are not 80 long\n",
    "df = df[df.genome_sequence.apply(lambda x: len(x)) == 80]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>genome_sequence</th>\n",
       "      <th>species</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11408003</td>\n",
       "      <td>ccacatcccctccagcacctgttgtttcctgactttttaatgattg...</td>\n",
       "      <td>Gorilla_gorilla</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18639873</td>\n",
       "      <td>tgtttacttgccaatctttgtttagctgtcagagtggcttgctaaa...</td>\n",
       "      <td>Gorilla_gorilla</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9869298</td>\n",
       "      <td>tctgtgaagaaagacattggtagcttgatggggatgacattgaatc...</td>\n",
       "      <td>Homo_sapiens</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10762804</td>\n",
       "      <td>ttgtgagaattacgtgagatgatagatttagggactatagaatagt...</td>\n",
       "      <td>Gorilla_gorilla</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13724428</td>\n",
       "      <td>gcaaaaaataagttgataagttgattgatatgttattagcttaatt...</td>\n",
       "      <td>Gorilla_gorilla</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                    genome_sequence  \\\n",
       "0  11408003  ccacatcccctccagcacctgttgtttcctgactttttaatgattg...   \n",
       "1  18639873  tgtttacttgccaatctttgtttagctgtcagagtggcttgctaaa...   \n",
       "2   9869298  tctgtgaagaaagacattggtagcttgatggggatgacattgaatc...   \n",
       "3  10762804  ttgtgagaattacgtgagatgatagatttagggactatagaatagt...   \n",
       "4  13724428  gcaaaaaataagttgataagttgattgatatgttattagcttaatt...   \n",
       "\n",
       "           species  label  \n",
       "0  Gorilla_gorilla      0  \n",
       "1  Gorilla_gorilla      0  \n",
       "2     Homo_sapiens      1  \n",
       "3  Gorilla_gorilla      0  \n",
       "4  Gorilla_gorilla      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a label column that change the species name into a number\n",
    "labels_dict = {species: i for i, species in enumerate(df.species.unique())}\n",
    "df[\"label\"] = df.species.map(labels_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to one hot encode a DNA sequence\n",
    "def one_hot_encote_dna(seq):\n",
    "    return np.array(\n",
    "        [\n",
    "            [\n",
    "                1 if c == \"A\" else 0,\n",
    "                1 if c == \"C\" else 0,\n",
    "                1 if c == \"G\" else 0,\n",
    "                1 if c == \"T\" else 0,\n",
    "            ]\n",
    "            for c in seq.upper()\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genome_sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ccacatcccctccagcacctgttgtttcctgactttttaatgattg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tgtttacttgccaatctttgtttagctgtcagagtggcttgctaaa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tctgtgaagaaagacattggtagcttgatggggatgacattgaatc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ttgtgagaattacgtgagatgatagatttagggactatagaatagt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gcaaaaaataagttgataagttgattgatatgttattagcttaatt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     genome_sequence  label\n",
       "0  ccacatcccctccagcacctgttgtttcctgactttttaatgattg...      0\n",
       "1  tgtttacttgccaatctttgtttagctgtcagagtggcttgctaaa...      0\n",
       "2  tctgtgaagaaagacattggtagcttgatggggatgacattgaatc...      1\n",
       "3  ttgtgagaattacgtgagatgatagatttagggactatagaatagt...      0\n",
       "4  gcaaaaaataagttgataagttgattgatatgttattagcttaatt...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=[\"id\", \"species\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train dataset:  (800000, 2)\n",
      "Shape of the test dataset:  (200000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train and test\n",
    "df_train, df_test = train_test_split(\n",
    "    df.sample(n=500000, random_state=random_state),\n",
    "    test_size=0.2,\n",
    "    random_state=random_state,\n",
    ")\n",
    "print(\"Shape of the train dataset: \", df_train.shape)\n",
    "print(\"Shape of the test dataset: \", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_vector(seq):\n",
    "    return one_hot_encote_dna(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom dataset\n",
    "class GenomeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        return encode_vector(row.genome_sequence), row.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets for df_train and test and dataloaders\n",
    "train_dataset = GenomeDataset(df_train)\n",
    "test_dataset = GenomeDataset(df_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=128, shuffle=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Deep neural network of input size 320 and output size 1\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GenomeClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(4, 4)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(80 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.flat(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = F.dropout(x, 0.05)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # x = F.dropout(x, 0.05)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        # x = F.dropout(x, 0.05)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "clf = GenomeClassifier()\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer_args = {\"lr\": 0.01, \"weight_decay\": 1e-5}\n",
    "optimizer = torch.optim.Adam(clf.parameters(), **optimizer_args)\n",
    "\n",
    "\n",
    "# Define a function to train the model\n",
    "def train(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.long())\n",
    "        loss = criterion(outputs.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [03:57<00:00, 26.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train loss: 0.694\n",
      "Accuracy: 0.499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [11:54<00:00,  8.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train loss: 0.693\n",
      "Accuracy: 0.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [13:36<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train loss: 0.693\n",
      "Accuracy: 0.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 265/6250 [00:37<14:16,  6.98it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Train\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     train_loss \u001b[39m=\u001b[39m train(clf, train_dataloader, criterion, optimizer)\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | Train loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[39m# Conpute accuracy\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[72], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, criterion, optimizer)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m i, (inputs, labels) \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(dataloader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(dataloader)):\n\u001b[1;32m     15\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 16\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs\u001b[39m.\u001b[39;49mlong())\n\u001b[1;32m     17\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs\u001b[39m.\u001b[39msqueeze(), labels\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m     18\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[71], line 18\u001b[0m, in \u001b[0;36mGenomeClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed(x)\n\u001b[1;32m     17\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflat(x)\n\u001b[0;32m---> 18\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x))\n\u001b[1;32m     19\u001b[0m \u001b[39m# x = F.dropout(x, 0.05)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x))\n",
      "File \u001b[0;32m~/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "for epoch in range(5):\n",
    "    train_loss = train(clf, train_dataloader, criterion, optimizer)\n",
    "    print(f\"Epoch {epoch + 1} | Train loss: {train_loss:.3f}\")\n",
    "    # Conpute accuracy\n",
    "    clf.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in test_dataloader:\n",
    "            outputs = clf(inputs.long())\n",
    "            predicted = torch.round(torch.sigmoid(outputs))\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.squeeze() == labels).sum().item()\n",
    "        print(f\"Accuracy: {correct / total:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLEARN GENETIC OPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
      "Requirement already satisfied: sklearn-genetic-opt in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (0.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from sklearn-genetic-opt) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from sklearn-genetic-opt) (1.24.3)\n",
      "Requirement already satisfied: deap>=1.3.3 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from sklearn-genetic-opt) (1.4.1)\n",
      "Requirement already satisfied: tqdm>=4.61.1 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from sklearn-genetic-opt) (4.66.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from scikit-learn>=1.1.0->sklearn-genetic-opt) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from scikit-learn>=1.1.0->sklearn-genetic-opt) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from scikit-learn>=1.1.0->sklearn-genetic-opt) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-genetic-opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 16:13:43.606296: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-14 16:13:44.936445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn_genetic.space import Categorical, Integer, Continuous\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"tol\": Continuous(1e-2, 1e10, distribution=\"log-uniform\"),\n",
    "    \"activation\": Categorical([\"logistic\", \"relu\", \"tanh\"]),\n",
    "    \"learning_rate\": Categorical([\"constant\", \"invscaling\", \"adaptive\"]),\n",
    "    \"hidden_layer_sizes\": Integer(10, 1000),\n",
    "    \"max_iter\": Integer(100, 1000),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The base classifier to tune\n",
    "clf = MLPClassifier(early_stopping=True, random_state=random_state)\n",
    "\n",
    "# Our cross-validation strategy (it could be just an int)\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# The main class from sklearn-genetic-opt\n",
    "evolved_estimator = GASearchCV(\n",
    "    estimator=clf,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\",\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    "    population_size=15,\n",
    "    generations=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tfitness\tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t5     \t0.50068\t0.00476979 \t0.5059     \t0.493901   \n",
      "1  \t10    \t0.505541\t0.00102873 \t0.506201   \t0.503501   \n",
      "2  \t10    \t0.505961\t0.000480594\t0.506201   \t0.505      \n",
      "3  \t10    \t0.506281\t0.000160116\t0.506601   \t0.5062     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/80 [05:23<7:05:37, 323.26s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     X_train, y_train \u001b[39m=\u001b[39m mini_batch\n\u001b[1;32m      7\u001b[0m     X_train \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mreshape(X_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     evolved_estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Score\u001b[39;00m\n\u001b[1;32m     11\u001b[0m mean_acc \u001b[39m=\u001b[39m \u001b[39m0.\u001b[39m\n",
      "File \u001b[0;32m~/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages/sklearn_genetic/genetic_search.py:492\u001b[0m, in \u001b[0;36mGASearchCV.fit\u001b[0;34m(self, X, y, callbacks)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_register()\n\u001b[1;32m    491\u001b[0m \u001b[39m# Optimization routine from the selected evolutionary algorithm\u001b[39;00m\n\u001b[0;32m--> 492\u001b[0m pop, log, n_gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_select_algorithm(pop\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pop, stats\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stats, hof\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_hof)\n\u001b[1;32m    494\u001b[0m \u001b[39m# Update the _n_iterations value as the algorithm could stop earlier due a callback\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_iterations \u001b[39m=\u001b[39m n_gen\n",
      "File \u001b[0;32m~/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages/sklearn_genetic/genetic_search.py:572\u001b[0m, in \u001b[0;36mGASearchCV._select_algorithm\u001b[0;34m(self, pop, stats, hof)\u001b[0m\n\u001b[1;32m    570\u001b[0m selected_algorithm \u001b[39m=\u001b[39m algorithms_factory\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    571\u001b[0m \u001b[39mif\u001b[39;00m selected_algorithm:\n\u001b[0;32m--> 572\u001b[0m     pop, log, gen \u001b[39m=\u001b[39m selected_algorithm(\n\u001b[1;32m    573\u001b[0m         pop,\n\u001b[1;32m    574\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoolbox,\n\u001b[1;32m    575\u001b[0m         mu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpopulation_size,\n\u001b[1;32m    576\u001b[0m         lambda_\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpopulation_size,\n\u001b[1;32m    577\u001b[0m         cxpb\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcrossover_adapter,\n\u001b[1;32m    578\u001b[0m         stats\u001b[39m=\u001b[39;49mstats,\n\u001b[1;32m    579\u001b[0m         mutpb\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutation_adapter,\n\u001b[1;32m    580\u001b[0m         ngen\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerations,\n\u001b[1;32m    581\u001b[0m         halloffame\u001b[39m=\u001b[39;49mhof,\n\u001b[1;32m    582\u001b[0m         callbacks\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallbacks,\n\u001b[1;32m    583\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    584\u001b[0m         estimator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    585\u001b[0m     )\n\u001b[1;32m    587\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    588\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    589\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe algorithm \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm\u001b[39m}\u001b[39;00m\u001b[39m is not supported, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    590\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mplease select one from \u001b[39m\u001b[39m{\u001b[39;00mAlgorithms\u001b[39m.\u001b[39mlist()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    591\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages/sklearn_genetic/algorithms.py:280\u001b[0m, in \u001b[0;36meaMuPlusLambda\u001b[0;34m(population, toolbox, mu, lambda_, cxpb, mutpb, ngen, stats, halloffame, callbacks, verbose, estimator, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m invalid_ind \u001b[39m=\u001b[39m [ind \u001b[39mfor\u001b[39;00m ind \u001b[39min\u001b[39;00m population \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ind\u001b[39m.\u001b[39mfitness\u001b[39m.\u001b[39mvalid]\n\u001b[1;32m    279\u001b[0m fitnesses \u001b[39m=\u001b[39m toolbox\u001b[39m.\u001b[39mmap(toolbox\u001b[39m.\u001b[39mevaluate, invalid_ind)\n\u001b[0;32m--> 280\u001b[0m \u001b[39mfor\u001b[39;00m ind, fit \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(invalid_ind, fitnesses):\n\u001b[1;32m    281\u001b[0m     ind\u001b[39m.\u001b[39mfitness\u001b[39m.\u001b[39mvalues \u001b[39m=\u001b[39m fit\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m halloffame \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages/sklearn_genetic/genetic_search.py:399\u001b[0m, in \u001b[0;36mGASearchCV.evaluate\u001b[0;34m(self, individual)\u001b[0m\n\u001b[1;32m    396\u001b[0m local_estimator\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcurrent_generation_params)\n\u001b[1;32m    398\u001b[0m \u001b[39m# Compute the cv-metrics\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    400\u001b[0m     local_estimator,\n\u001b[1;32m    401\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX_,\n\u001b[1;32m    402\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_,\n\u001b[1;32m    403\u001b[0m     cv\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv,\n\u001b[1;32m    404\u001b[0m     scoring\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscoring,\n\u001b[1;32m    405\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    406\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpre_dispatch,\n\u001b[1;32m    407\u001b[0m     error_score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score,\n\u001b[1;32m    408\u001b[0m     return_train_score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_train_score,\n\u001b[1;32m    409\u001b[0m )\n\u001b[1;32m    411\u001b[0m cv_scores \u001b[39m=\u001b[39m cv_results[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefit_metric\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    412\u001b[0m score \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(cv_scores)\n",
      "File \u001b[0;32m~/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    311\u001b[0m         clone(estimator),\n\u001b[1;32m    312\u001b[0m         X,\n\u001b[1;32m    313\u001b[0m         y,\n\u001b[1;32m    314\u001b[0m         scorers,\n\u001b[1;32m    315\u001b[0m         train,\n\u001b[1;32m    316\u001b[0m         test,\n\u001b[1;32m    317\u001b[0m         verbose,\n\u001b[1;32m    318\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    319\u001b[0m         fit_params,\n\u001b[1;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    324\u001b[0m     )\n\u001b[1;32m    325\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m indices\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=10000, shuffle=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=10000, shuffle=True\n",
    ")\n",
    "\n",
    "for mini_batch in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "    X_train, y_train = mini_batch\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    evolved_estimator.fit(X_train, y_train)\n",
    "\n",
    "# Score\n",
    "mean_acc = 0.0\n",
    "for mini_batch in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "    X_test, y_test = mini_batch\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "    y_pred = evolved_estimator.predict(X_test)\n",
    "\n",
    "    mean_acc += accuracy_score(y_test, y_pred)\n",
    "mean_acc /= len(test_dataloader)\n",
    "\n",
    "print(f\"Mean accuracy per mini_batch: {mean_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb#scrollTo=ikfbFlNHgi8T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
      "Requirement already satisfied: transformers in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (4.34.0)\n",
      "Requirement already satisfied: filelock in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/arnaudb/Documents/EPITA/ING3/ml-bio/.venv/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2a7a39c5c840419a06a2f456ad5fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/46.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008f43dddc3a4ab48494e5708609d01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.54M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eddcf49bc5d4135a5911a88264b30d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sections of config\n",
    "\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 100\n",
    "TRAIN_BATCH_SIZE = 512\n",
    "VALID_BATCH_SIZE = 256\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-03\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"AIRI-Institute/gena-lm-bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.genome_sequence = dataframe.genome_sequence\n",
    "        self.targets = dataframe.label.to_numpy()\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.genome_sequence)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        genome_seq = str(self.genome_sequence.iloc[index])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            genome_seq,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
    "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            \"targets\": torch.tensor(self.targets[index], dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (19799984, 2)\n",
      "TRAIN Dataset: (800000, 2)\n",
      "TEST Dataset: (200000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(df_train.shape))\n",
    "print(\"TEST Dataset: {}\".format(df_test.shape))\n",
    "\n",
    "training_set = CustomDataset(df_train, tokenizer, MAX_LEN)\n",
    "testing_set = CustomDataset(df_test, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\"batch_size\": TRAIN_BATCH_SIZE, \"shuffle\": True, \"num_workers\": 0}\n",
    "\n",
    "test_params = {\"batch_size\": VALID_BATCH_SIZE, \"shuffle\": True, \"num_workers\": 0}\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at AIRI-Institute/gena-lm-bert-base and are newly initialized: ['bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=3)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Dropout(p=0.3, inplace=False)\n",
       "  (l3): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model.\n",
    "\n",
    "\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "\n",
    "        self.l1 = AutoModel.from_pretrained(\"AIRI-Institute/gena-lm-bert-base\")\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output_1 = self.l1(\n",
    "            ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False\n",
    "        )\n",
    "        output_2 = self.l2(output_1)\n",
    "        output = self.l3(output_2)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "model = BERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for _, data in enumerate(training_loader, 0):\n",
    "        ids = data[\"ids\"].to(device, dtype=torch.long)\n",
    "        mask = data[\"mask\"].to(device, dtype=torch.long)\n",
    "        token_type_ids = data[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "        targets = data[\"targets\"].to(device, dtype=torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        if _ % 1 == 0:\n",
    "            print(f\"Epoch: {epoch}, Loss:  {loss.item()}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data[\"ids\"].to(device, dtype=torch.long)\n",
    "            mask = data[\"mask\"].to(device, dtype=torch.long)\n",
    "            token_type_ids = data[\"token_type_ids\"].to(device, dtype=torch.long)\n",
    "            targets = data[\"targets\"].to(device, dtype=torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    outputs, targets = validation(epoch)\n",
    "    outputs = np.array(outputs) >= 0.5\n",
    "    accuracy = metrics.accuracy_score(targets, outputs)\n",
    "    f1_score_micro = metrics.f1_score(targets, outputs, average=\"micro\")\n",
    "    f1_score_macro = metrics.f1_score(targets, outputs, average=\"macro\")\n",
    "    print(f\"Accuracy Score = {accuracy}\")\n",
    "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "    print(f\"F1 Score (Macro) = {f1_score_macro}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a torch dataset for convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset for CNN\n",
    "class GenomeDatasetCNN(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = (\n",
    "            transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "            if transform is None\n",
    "            else transform\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        label = row.label\n",
    "        dna = row.genome_sequence\n",
    "        dna = one_hot_encote_dna(dna)\n",
    "        dna = torch.from_numpy(dna)\n",
    "        dna = torch.reshape(dna, (dna.shape[1], dna.shape[0]))\n",
    "        # convert all to float\n",
    "        dna = dna.float()\n",
    "        label = torch.tensor(label).float()\n",
    "        return dna, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_one_hot_encoded_dna(genome_seq):\n",
    "    # Plot the one hot encoded DNA sequence\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    plt.imshow(genome_seq, cmap=\"hot\")\n",
    "    plt.xticks(range(0, genome_seq.shape[0]))\n",
    "    plt.yticks(range(0, 4), [\"A\", \"C\", \"G\", \"T\"])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "test_print = one_hot_encote_dna(df_train.iloc[0].genome_sequence).transpose(1, 0)\n",
    "print_one_hot_encoded_dna(test_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA shape:  torch.Size([32, 4, 80])\n",
      "Label shape:  torch.Size([32])\n",
      "Label:  tensor([0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.])\n",
      "DNA:  tensor([[0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "         1., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 1., 0., 0., 1., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = GenomeDatasetCNN(df_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32)\n",
    "\n",
    "# print an example of the dataset\n",
    "dna, label = next(iter(dataloader))\n",
    "print(\"DNA shape: \", dna.shape)\n",
    "print(\"Label shape: \", label.shape)\n",
    "print(\"Label: \", label)\n",
    "print(\"DNA: \", dna[0])\n",
    "print_one_hot_encoded_dna(dna[0])  # Print the first DNA sequence of the batch\n",
    "\n",
    "# Make our test and train datasets and data loaders\n",
    "train_dataset = GenomeDatasetCNN(df_train)\n",
    "test_dataset = GenomeDatasetCNN(df_test)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=256, shuffle=True, drop_last=True\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the model\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        # In channel: 4\n",
    "        # Use 3 layers of Conv1D with kernel size (2, 3, 3) and stride (0, 1, 1), and padding (0, 1, 1)\n",
    "        The in channels are: (4, 16, 32)\n",
    "        The out channels are: (16, 32, 64)\n",
    "        # Use 1 layer of MaxPool1D with kernel size (2) and stride (2)\n",
    "        # Use 2 layers of Linear with 128 and 64 neurons\n",
    "        # Use 1 layer of Linear with 1 neuron\n",
    "        \"\"\"\n",
    "\n",
    "        self.conv1 = nn.Conv1d(4, 16, 2, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv1d(16, 32, 3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(32, 64, 3, stride=1, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(16)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(32)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(64)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(19 * 64, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout(x)\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for batch_idx, (genome_seq, label) in enumerate(dataloader):\n",
    "        output = model(genome_seq)\n",
    "        y_true.extend(label.numpy())\n",
    "        y_pred.extend(output.argmax(axis=1).numpy())\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    dataloader,\n",
    "    epochs=10,\n",
    "    device=\"cpu\",\n",
    "    test_dataloader=None,\n",
    "):\n",
    "    model.to(device)\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_accuracy = 0\n",
    "        for batch_idx, (genome_seq, label) in tqdm(\n",
    "            enumerate(dataloader), total=len(dataloader)\n",
    "        ):\n",
    "            optimizer.zero_grad()\n",
    "            genome_seq = genome_seq.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(genome_seq)\n",
    "            loss = criterion(output.view(-1), label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_accuracy += accuracy_score(\n",
    "                label.cpu().numpy(), output.argmax(axis=1).cpu().numpy()\n",
    "            )\n",
    "\n",
    "        print(\"Train loss: \", train_loss / len(dataloader))\n",
    "        losses.append(train_loss / len(dataloader))\n",
    "        print(\"Train accuracy: \", train_accuracy / len(dataloader))\n",
    "\n",
    "        # Test the model\n",
    "        if test_dataloader is not None:\n",
    "            accuracy = compute_accuracy(model, test_dataloader)\n",
    "            print(\"Test accuracy: \", accuracy)\n",
    "            accuracies.append((accuracy, train_accuracy / len(dataloader)))\n",
    "\n",
    "    return model, losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [04:58<00:00, 10.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.6899812900161744\n",
      "Train accuracy:  0.5007975\n",
      "Test accuracy:  0.49898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [04:41<00:00, 11.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.6897934108543397\n",
      "Train accuracy:  0.5007975\n",
      "Test accuracy:  0.49898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [04:29<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.689638861618042\n",
      "Train accuracy:  0.5007975\n",
      "Test accuracy:  0.49898\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable CNN object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, losses, accuracies \u001b[39m=\u001b[39m train_model(model, optimizer, criterion, train_dataloader, epochs\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, device\u001b[39m=\u001b[39mdevice, test_dataloader\u001b[39m=\u001b[39mtest_dataloader)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable CNN object"
     ]
    }
   ],
   "source": [
    "model = train_model(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_dataloader,\n",
    "    epochs=3,\n",
    "    device=device,\n",
    "    test_dataloader=test_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set:  0.49898\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy on the test set\n",
    "print(\"Accuracy on the test set: \", compute_accuracy(model, test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot accuracy and loss\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(accuracies)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(losses)\n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
