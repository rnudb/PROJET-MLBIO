{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nIn the realm of genomics, understanding the distinct genetic variations among different species is crucial. One application of this understanding is the classification of DNA sequences, which can, for instance, differentiate between human and gorilla DNA. This analysis aims to investigate various machine learning approaches to classify given DNA sequences into one of these two categories, leveraging a dataset provided in the Kaggle competition, [ML Olympiad - Genome Sequences Classification](https://www.kaggle.com/competitions/ml-olympiad-gdscuiz-and-tfugagadir/data).\n\nThe dataset comprises sequences of DNA, each labeled as either 'human' or 'gorilla'. The primary goal is to build and compare models that can accurately predict these labels based on the DNA sequences. Five different approaches will be explored:\n- Convolutional Neural Networks (CNN)\n- Pre-trained BERT model specialized for genomic sequences\n- Long Short-Term Memory networks (LSTM)\n- Random Forest\n- Multi Layer Perceptron (MLP)\n\nThrough this analysis, we aim to discern which model or combination of models yields the highest accuracy in classifying the DNA sequences. Additionally, we will look into potential improvements and optimizations to enhance the performance of the chosen models.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Dataset\nThe dataset provided in the [ML Olympiad - Genome Sequences Classification competition](https://www.kaggle.com/competitions/ml-olympiad-gdscuiz-and-tfugagadir/data) consists of DNA sequences labeled as either 'human' or 'gorilla'. In this section, we'll explore the dataset to understand its structure, size, and the distribution of labels. We'll also conduct some preliminary analysis to identify any potential challenges or considerations for the subsequent modeling steps.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load the dataset\ndata = pd.read_csv('../input/ml-olympiad-gdscuiz-and-tfugagadir/train.csv')\n\n# Display the first few rows of the dataset\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-14T16:19:26.566715Z","iopub.execute_input":"2023-10-14T16:19:26.567090Z","iopub.status.idle":"2023-10-14T16:20:20.019700Z","shell.execute_reply.started":"2023-10-14T16:19:26.567057Z","shell.execute_reply":"2023-10-14T16:20:20.018756Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0        id                                    genome_sequence  \\\n0           0  11408003  ccacatcccctccagcacctgttgtttcctgactttttaatgattg...   \n1           1  18639873  tgtttacttgccaatctttgtttagctgtcagagtggcttgctaaa...   \n2           2   9869298  tctgtgaagaaagacattggtagcttgatggggatgacattgaatc...   \n3           3  10762804  ttgtgagaattacgtgagatgatagatttagggactatagaatagt...   \n4           4  13724428  gcaaaaaataagttgataagttgattgatatgttattagcttaatt...   \n\n           species  \n0  Gorilla_gorilla  \n1  Gorilla_gorilla  \n2     Homo_sapiens  \n3  Gorilla_gorilla  \n4  Gorilla_gorilla  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>genome_sequence</th>\n      <th>species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>11408003</td>\n      <td>ccacatcccctccagcacctgttgtttcctgactttttaatgattg...</td>\n      <td>Gorilla_gorilla</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>18639873</td>\n      <td>tgtttacttgccaatctttgtttagctgtcagagtggcttgctaaa...</td>\n      <td>Gorilla_gorilla</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>9869298</td>\n      <td>tctgtgaagaaagacattggtagcttgatggggatgacattgaatc...</td>\n      <td>Homo_sapiens</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>10762804</td>\n      <td>ttgtgagaattacgtgagatgatagatttagggactatagaatagt...</td>\n      <td>Gorilla_gorilla</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>13724428</td>\n      <td>gcaaaaaataagttgataagttgattgatatgttattagcttaatt...</td>\n      <td>Gorilla_gorilla</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's lower the row count to speed up the analysis, as we won't use that much data anyway.","metadata":{}},{"cell_type":"code","source":"data = data.sample(n=1000000)","metadata":{"execution":{"iopub.status.busy":"2023-10-14T16:20:20.021632Z","iopub.execute_input":"2023-10-14T16:20:20.021951Z","iopub.status.idle":"2023-10-14T16:20:21.345840Z","shell.execute_reply.started":"2023-10-14T16:20:20.021920Z","shell.execute_reply":"2023-10-14T16:20:21.344817Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Structure\nLet's start by examining the structure of the dataset including the number of samples, features, and the distribution of labels.","metadata":{}},{"cell_type":"code","source":"# Getting the shape of the dataset\ndataset_shape = data.shape\nprint(f'The dataset contains {dataset_shape[0]} samples and {dataset_shape[1]} columns.')\n\n# Checking the distribution of labels\nlabel_distribution = data['species'].value_counts(normalize=True)\nlabel_distribution","metadata":{"execution":{"iopub.status.busy":"2023-10-14T14:27:21.105710Z","iopub.execute_input":"2023-10-14T14:27:21.106036Z","iopub.status.idle":"2023-10-14T14:27:21.182208Z","shell.execute_reply.started":"2023-10-14T14:27:21.106009Z","shell.execute_reply":"2023-10-14T14:27:21.180844Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"The dataset contains 1000000 samples and 4 columns.\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"species\nHomo_sapiens       0.500214\nGorilla_gorilla    0.499786\nName: proportion, dtype: float64"},"metadata":{}}]},{"cell_type":"markdown","source":"## Preliminary Analysis\nWe'll conduct some preliminary analysis to better understand the characteristics of the DNA sequences. This includes examining the length of the sequences, the distribution of nucleotide bases (A, C, G, T), and any missing or anomalous values.","metadata":{}},{"cell_type":"code","source":"# Checking for missing values\nmissing_values = data.isnull().sum()\nmissing_values","metadata":{"execution":{"iopub.status.busy":"2023-10-14T14:27:42.705896Z","iopub.execute_input":"2023-10-14T14:27:42.706241Z","iopub.status.idle":"2023-10-14T14:27:42.960585Z","shell.execute_reply.started":"2023-10-14T14:27:42.706216Z","shell.execute_reply":"2023-10-14T14:27:42.959597Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0         0\nid                 0\ngenome_sequence    0\nspecies            0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Exploring the length of DNA sequences\nsequence_lengths = data['genome_sequence'].apply(len)\nsequence_lengths.describe()","metadata":{"execution":{"iopub.status.busy":"2023-10-14T14:27:43.775962Z","iopub.execute_input":"2023-10-14T14:27:43.776299Z","iopub.status.idle":"2023-10-14T14:27:44.223899Z","shell.execute_reply.started":"2023-10-14T14:27:43.776274Z","shell.execute_reply":"2023-10-14T14:27:44.222989Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"count    1000000.000000\nmean          79.999977\nstd            0.023000\nmin           57.000000\n25%           80.000000\n50%           80.000000\n75%           80.000000\nmax           80.000000\nName: genome_sequence, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"# Function to count the occurrences of each nucleotide in a sequence\n# Concatenating all sequences into a single string\nall_sequences = ''.join(data['genome_sequence'])\n\n# Counting the occurrences of each nucleotide\nbase_counts = pd.Series({'a': all_sequences.count('a'), \n                         'c': all_sequences.count('c'), \n                         'g': all_sequences.count('g'), \n                         't': all_sequences.count('t')})\n\n# Displaying the counts\nbase_counts","metadata":{"execution":{"iopub.status.busy":"2023-10-14T14:43:12.460023Z","iopub.execute_input":"2023-10-14T14:43:12.460359Z","iopub.status.idle":"2023-10-14T14:43:14.160768Z","shell.execute_reply.started":"2023-10-14T14:43:12.460332Z","shell.execute_reply":"2023-10-14T14:43:14.159709Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"a    23912760\nc    16068705\ng    15967064\nt    24051448\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"The preliminary analysis provides insight into the basic characteristics of the DNA sequences in the dataset. The findings from this section will inform the choice and configuration of machine learning models in the subsequent steps of this analysis.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Approaches\nIn this section, we explore various machine learning approaches to classify the DNA sequences as either human or gorilla. The models chosen for this analysis span a range of complexities and methodologies, from traditional machine learning to deep learning architectures. The objective is to compare the performance and insights gleaned from each model, thereby identifying the most effective strategy for this classification task. The approaches considered include Convolutional Neural Networks (CNN), a genomic sequences pre-trained BERT model, Long Short-Term Memory networks (LSTM), Random Forest, and Multi Layer Perceptron (MLP).","metadata":{}},{"cell_type":"markdown","source":"## Convolutional Neural Networks (CNN)\nConvolutional Neural Networks (CNN) are particularly adept at identifying patterns in spatial or temporal data, making them a suitable choice for sequence data like DNA sequences. The convolution layers can detect motifs in the DNA sequences which can be crucial for accurate classification.","metadata":{}},{"cell_type":"code","source":"# Placeholder for CNN model code","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Genomic Sequences Pre-trained BERT\nThe Bidirectional Encoder Representations from Transformers (BERT) model has shown promise in various NLP tasks. A version of BERT pre-trained on genomic sequences can potentially capture the contextual relationships between nucleotides in DNA sequences, thereby aiding in accurate classification.","metadata":{}},{"cell_type":"code","source":"# Placeholder for genomic sequences pre-trained BERT model code","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Long Short-Term Memory Networks (LSTM)\nLong Short-Term Memory networks (LSTM) are a type of recurrent neural network capable of learning long-term dependencies in data. Given the sequential nature of DNA, LSTMs can be employed to capture the inherent dependencies between nucleotides over varying sequence lengths.","metadata":{}},{"cell_type":"code","source":"# Placeholder for LSTM model code","metadata":{"execution":{"iopub.status.busy":"2023-10-14T14:33:05.876447Z","iopub.execute_input":"2023-10-14T14:33:05.876764Z","iopub.status.idle":"2023-10-14T14:33:05.881267Z","shell.execute_reply.started":"2023-10-14T14:33:05.876740Z","shell.execute_reply":"2023-10-14T14:33:05.880155Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Random Forest\nRandom Forest is a versatile and robust machine learning algorithm capable of handling a mix of data types. By encoding the DNA sequences appropriately, Random Forest can be utilized to identify the distinguishing features between human and gorilla DNA.","metadata":{}},{"cell_type":"code","source":"pip install optuna","metadata":{"execution":{"iopub.status.busy":"2023-10-14T16:20:21.347384Z","iopub.execute_input":"2023-10-14T16:20:21.348041Z","iopub.status.idle":"2023-10-14T16:20:31.336357Z","shell.execute_reply.started":"2023-10-14T16:20:21.348002Z","shell.execute_reply":"2023-10-14T16:20:31.335090Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.3.0)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.12.0)\nRequirement already satisfied: cmaes>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (0.10.0)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.7.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.17)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.1)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.2.4)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.0.9)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import optuna\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.feature_extraction.text import HashingVectorizer","metadata":{"execution":{"iopub.status.busy":"2023-10-14T16:24:11.795708Z","iopub.execute_input":"2023-10-14T16:24:11.796065Z","iopub.status.idle":"2023-10-14T16:24:11.801128Z","shell.execute_reply.started":"2023-10-14T16:24:11.796037Z","shell.execute_reply":"2023-10-14T16:24:11.799882Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"data_1000 = data.sample(n=1000000//10)","metadata":{"execution":{"iopub.status.busy":"2023-10-14T16:27:15.996740Z","iopub.execute_input":"2023-10-14T16:27:15.997135Z","iopub.status.idle":"2023-10-14T16:27:16.138750Z","shell.execute_reply.started":"2023-10-14T16:27:15.997105Z","shell.execute_reply":"2023-10-14T16:27:16.137682Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Getting the shape of the dataset\ndataset_shape = data_1000.shape\nprint(f'The dataset contains {dataset_shape[0]} samples and {dataset_shape[1]} columns.')\n\n# Checking the distribution of labels\nlabel_distribution = data_1000['species'].value_counts(normalize=True)\nlabel_distribution","metadata":{"execution":{"iopub.status.busy":"2023-10-14T16:27:16.678964Z","iopub.execute_input":"2023-10-14T16:27:16.679560Z","iopub.status.idle":"2023-10-14T16:27:16.697403Z","shell.execute_reply.started":"2023-10-14T16:27:16.679528Z","shell.execute_reply":"2023-10-14T16:27:16.696332Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"The dataset contains 100000 samples and 4 columns.\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"species\nHomo_sapiens       0.50028\nGorilla_gorilla    0.49972\nName: proportion, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"# Define a function to convert a DNA sequence into overlapping k-mers\ndef kmerizer(seq, k=6):\n    return [seq[i:i+k] for i in range(len(seq) - k + 1)]\n\n# Test the function with a single DNA sequence\n# print(get_kmers(data_1000['genome_sequence'][0]))\n\nhash_vectorizer = HashingVectorizer(analyzer=kmerizer, n_features=2**20)  # Adjust n_features to manage memory usage\n\n# Apply the vectorizer to the genome_sequence column of the DataFrame\nX = hash_vectorizer.fit_transform(data_1000['genome_sequence'])\n\n# Encode species labels\ndata_1000['species_encoded'] = data_1000['species'].map({'Homo_sapiens': 0, 'Gorilla_gorilla': 1})\ny = data_1000['species_encoded']\n\n# Split dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-10-14T16:27:17.305751Z","iopub.execute_input":"2023-10-14T16:27:17.306094Z","iopub.status.idle":"2023-10-14T16:27:19.919954Z","shell.execute_reply.started":"2023-10-14T16:27:17.306066Z","shell.execute_reply":"2023-10-14T16:27:19.918677Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    # Hyperparameters to be optimized\n    n_estimators = trial.suggest_int('n_estimators', 10, 200)  # Expanded range\n    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss'])\n    max_depth = trial.suggest_int('max_depth', 2, 32, log=True)\n    min_samples_split = trial.suggest_float('min_samples_split', 0.1, 1)\n    min_samples_leaf = trial.suggest_float('min_samples_leaf', 0.1, 0.5)\n    min_weight_fraction_leaf = trial.suggest_float('min_weight_fraction_leaf', 0.0, 0.5)\n    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])\n    max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 2, 128, log=True)\n    min_impurity_decrease = trial.suggest_float('min_impurity_decrease', 0.0, 1.0)\n    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n\n    classifier = RandomForestClassifier(\n        n_estimators=n_estimators,\n        criterion=criterion,\n        max_depth=max_depth,\n        min_samples_split=min_samples_split,\n        min_samples_leaf=min_samples_leaf,\n        min_weight_fraction_leaf=min_weight_fraction_leaf,\n        max_features=max_features,\n        max_leaf_nodes=max_leaf_nodes,\n        min_impurity_decrease=min_impurity_decrease,\n        bootstrap=bootstrap,\n        random_state=50\n    )\n\n    classifier.fit(X_train, y_train)\n    predictions = classifier.predict(X_test)\n    accuracy = accuracy_score(y_test, predictions)\n    return accuracy\n\noptuna.logging.set_verbosity(optuna.logging.INFO)\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)\n\n# Results of the optimization\nprint(f'Number of finished trials: {len(study.trials)}')\nprint(f'Best trial: {study.best_trial.params}')","metadata":{"execution":{"iopub.status.busy":"2023-10-14T16:32:36.544197Z","iopub.execute_input":"2023-10-14T16:32:36.544870Z","iopub.status.idle":"2023-10-14T16:35:53.957939Z","shell.execute_reply.started":"2023-10-14T16:32:36.544841Z","shell.execute_reply":"2023-10-14T16:35:53.956785Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"[I 2023-10-14 16:32:36,549] A new study created in memory with name: no-name-79f3cd72-899e-40a2-b59b-bcd6eb355275\n[I 2023-10-14 16:32:39,620] Trial 0 finished with value: 0.49965 and parameters: {'n_estimators': 158, 'criterion': 'log_loss', 'max_depth': 17, 'min_samples_split': 0.3880243171996576, 'min_samples_leaf': 0.4247838122008928, 'min_weight_fraction_leaf': 0.170287707952885, 'max_features': 'log2', 'max_leaf_nodes': 7, 'min_impurity_decrease': 0.6467542020296969, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:32:40,715] Trial 1 finished with value: 0.49965 and parameters: {'n_estimators': 52, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 0.44074976665665155, 'min_samples_leaf': 0.34299833723703405, 'min_weight_fraction_leaf': 0.10290971441725894, 'max_features': 'auto', 'max_leaf_nodes': 43, 'min_impurity_decrease': 0.6302062786681768, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:32:41,472] Trial 2 finished with value: 0.49965 and parameters: {'n_estimators': 33, 'criterion': 'log_loss', 'max_depth': 2, 'min_samples_split': 0.32432136464410743, 'min_samples_leaf': 0.14442764463945545, 'min_weight_fraction_leaf': 0.32342390619851286, 'max_features': 'sqrt', 'max_leaf_nodes': 2, 'min_impurity_decrease': 0.4434399406963455, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:32:44,567] Trial 3 finished with value: 0.49965 and parameters: {'n_estimators': 163, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 0.11198761313685379, 'min_samples_leaf': 0.41279906821281565, 'min_weight_fraction_leaf': 0.24361208195277767, 'max_features': 'auto', 'max_leaf_nodes': 6, 'min_impurity_decrease': 0.12083561398325782, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:32:45,402] Trial 4 finished with value: 0.49965 and parameters: {'n_estimators': 35, 'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 0.2849055239040029, 'min_samples_leaf': 0.4210652164704197, 'min_weight_fraction_leaf': 0.09901015366556265, 'max_features': 'sqrt', 'max_leaf_nodes': 61, 'min_impurity_decrease': 0.8171800125686763, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:32:46,776] Trial 5 finished with value: 0.49965 and parameters: {'n_estimators': 67, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 0.3668027502782485, 'min_samples_leaf': 0.20838706376290098, 'min_weight_fraction_leaf': 0.34456922877704144, 'max_features': 'auto', 'max_leaf_nodes': 5, 'min_impurity_decrease': 0.33241204783473677, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:32:48,127] Trial 6 finished with value: 0.49965 and parameters: {'n_estimators': 62, 'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 0.42717651635221665, 'min_samples_leaf': 0.24182270485086838, 'min_weight_fraction_leaf': 0.2174859684450981, 'max_features': 'log2', 'max_leaf_nodes': 10, 'min_impurity_decrease': 0.03988964896269953, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:32:51,576] Trial 7 finished with value: 0.49965 and parameters: {'n_estimators': 153, 'criterion': 'entropy', 'max_depth': 28, 'min_samples_split': 0.5350003309396081, 'min_samples_leaf': 0.22695107267479894, 'min_weight_fraction_leaf': 0.23551248957093918, 'max_features': 'sqrt', 'max_leaf_nodes': 87, 'min_impurity_decrease': 0.19966672270803043, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:32:53,974] Trial 8 finished with value: 0.49965 and parameters: {'n_estimators': 120, 'criterion': 'log_loss', 'max_depth': 7, 'min_samples_split': 0.23734093021932653, 'min_samples_leaf': 0.2610330166593675, 'min_weight_fraction_leaf': 0.020146752371912213, 'max_features': 'sqrt', 'max_leaf_nodes': 40, 'min_impurity_decrease': 0.39152251552950745, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:32:54,934] Trial 9 finished with value: 0.49965 and parameters: {'n_estimators': 44, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 0.5673002359018897, 'min_samples_leaf': 0.25377603693815326, 'min_weight_fraction_leaf': 0.15244490998086307, 'max_features': 'auto', 'max_leaf_nodes': 3, 'min_impurity_decrease': 0.6241885877006351, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:32:59,356] Trial 10 finished with value: 0.49965 and parameters: {'n_estimators': 190, 'criterion': 'log_loss', 'max_depth': 32, 'min_samples_split': 0.7875475395472189, 'min_samples_leaf': 0.35610709880975017, 'min_weight_fraction_leaf': 0.4828800447502953, 'max_features': 'log2', 'max_leaf_nodes': 17, 'min_impurity_decrease': 0.7733068206130589, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:33:01,265] Trial 11 finished with value: 0.49965 and parameters: {'n_estimators': 96, 'criterion': 'entropy', 'max_depth': 14, 'min_samples_split': 0.5563491062551652, 'min_samples_leaf': 0.4984630116695839, 'min_weight_fraction_leaf': 0.09393305626569978, 'max_features': 'log2', 'max_leaf_nodes': 27, 'min_impurity_decrease': 0.9916008681144797, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:33:03,470] Trial 12 finished with value: 0.49965 and parameters: {'n_estimators': 111, 'criterion': 'log_loss', 'max_depth': 15, 'min_samples_split': 0.9867659546016241, 'min_samples_leaf': 0.33195012140526975, 'min_weight_fraction_leaf': 0.03361472952885025, 'max_features': 'log2', 'max_leaf_nodes': 15, 'min_impurity_decrease': 0.5643864993498957, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:33:03,904] Trial 13 finished with value: 0.49965 and parameters: {'n_estimators': 13, 'criterion': 'log_loss', 'max_depth': 9, 'min_samples_split': 0.4751930635804304, 'min_samples_leaf': 0.37260452819893547, 'min_weight_fraction_leaf': 0.16568200597890467, 'max_features': 'auto', 'max_leaf_nodes': 111, 'min_impurity_decrease': 0.6169711433149067, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:33:06,577] Trial 14 finished with value: 0.49965 and parameters: {'n_estimators': 136, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 0.692058149855698, 'min_samples_leaf': 0.3215661041817209, 'min_weight_fraction_leaf': 0.0970831177044085, 'max_features': 'log2', 'max_leaf_nodes': 35, 'min_impurity_decrease': 0.5133925400185395, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:33:10,231] Trial 15 finished with value: 0.49965 and parameters: {'n_estimators': 194, 'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 0.4260927302778763, 'min_samples_leaf': 0.45911213871356304, 'min_weight_fraction_leaf': 0.12439289472109698, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 0.7129383399032205, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:33:11,939] Trial 16 finished with value: 0.49965 and parameters: {'n_estimators': 85, 'criterion': 'log_loss', 'max_depth': 10, 'min_samples_split': 0.19929383519736557, 'min_samples_leaf': 0.39503831527859745, 'min_weight_fraction_leaf': 0.005398772906051119, 'max_features': 'auto', 'max_leaf_nodes': 24, 'min_impurity_decrease': 0.7025400867540506, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:33:15,387] Trial 17 finished with value: 0.49965 and parameters: {'n_estimators': 168, 'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 0.351346582868861, 'min_samples_leaf': 0.3007866252229398, 'min_weight_fraction_leaf': 0.18916580873655714, 'max_features': 'log2', 'max_leaf_nodes': 54, 'min_impurity_decrease': 0.48785581076397505, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:33:17,897] Trial 18 finished with value: 0.49965 and parameters: {'n_estimators': 128, 'criterion': 'log_loss', 'max_depth': 10, 'min_samples_split': 0.15807783940746373, 'min_samples_leaf': 0.4469831285354705, 'min_weight_fraction_leaf': 0.05953740974162959, 'max_features': 'auto', 'max_leaf_nodes': 21, 'min_impurity_decrease': 0.3000455988480033, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:33:19,530] Trial 19 finished with value: 0.49965 and parameters: {'n_estimators': 82, 'criterion': 'gini', 'max_depth': 22, 'min_samples_split': 0.2660651648077958, 'min_samples_leaf': 0.36317257303185535, 'min_weight_fraction_leaf': 0.14740483415144334, 'max_features': 'log2', 'max_leaf_nodes': 11, 'min_impurity_decrease': 0.8684941443804228, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:33:22,466] Trial 20 finished with value: 0.49965 and parameters: {'n_estimators': 143, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.20649934912389678, 'min_samples_leaf': 0.2919354272179343, 'min_weight_fraction_leaf': 0.18310865826394584, 'max_features': 'log2', 'max_leaf_nodes': 6, 'min_impurity_decrease': 0.5980885075429674, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:33:22,902] Trial 21 finished with value: 0.49965 and parameters: {'n_estimators': 13, 'criterion': 'log_loss', 'max_depth': 2, 'min_samples_split': 0.3283144741093965, 'min_samples_leaf': 0.11483011405203697, 'min_weight_fraction_leaf': 0.2809280519780693, 'max_features': 'sqrt', 'max_leaf_nodes': 3, 'min_impurity_decrease': 0.46784539329560004, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:33:23,741] Trial 22 finished with value: 0.49965 and parameters: {'n_estimators': 35, 'criterion': 'log_loss', 'max_depth': 2, 'min_samples_split': 0.36813693543687787, 'min_samples_leaf': 0.16629545745570362, 'min_weight_fraction_leaf': 0.28027141428792135, 'max_features': 'sqrt', 'max_leaf_nodes': 2, 'min_impurity_decrease': 0.4395682751731772, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:33:24,883] Trial 23 finished with value: 0.49965 and parameters: {'n_estimators': 52, 'criterion': 'log_loss', 'max_depth': 3, 'min_samples_split': 0.2891357838615928, 'min_samples_leaf': 0.17243657370500193, 'min_weight_fraction_leaf': 0.33033960457405903, 'max_features': 'sqrt', 'max_leaf_nodes': 2, 'min_impurity_decrease': 0.5406386973622795, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:33:26,399] Trial 24 finished with value: 0.49965 and parameters: {'n_estimators': 72, 'criterion': 'log_loss', 'max_depth': 2, 'min_samples_split': 0.45013536450206537, 'min_samples_leaf': 0.29136830674958475, 'min_weight_fraction_leaf': 0.05677302830128282, 'max_features': 'sqrt', 'max_leaf_nodes': 8, 'min_impurity_decrease': 0.6700051619595114, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:33:27,126] Trial 25 finished with value: 0.49965 and parameters: {'n_estimators': 25, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 0.37575963778275095, 'min_samples_leaf': 0.34484361345755343, 'min_weight_fraction_leaf': 0.19939713187625674, 'max_features': 'sqrt', 'max_leaf_nodes': 4, 'min_impurity_decrease': 0.40213656944405457, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:33:29,534] Trial 26 finished with value: 0.49965 and parameters: {'n_estimators': 103, 'criterion': 'log_loss', 'max_depth': 8, 'min_samples_split': 0.2969312890899545, 'min_samples_leaf': 0.3870952394224016, 'min_weight_fraction_leaf': 0.12809338767943826, 'max_features': 'auto', 'max_leaf_nodes': 15, 'min_impurity_decrease': 0.5427976727518339, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:33:30,668] Trial 27 finished with value: 0.49965 and parameters: {'n_estimators': 53, 'criterion': 'log_loss', 'max_depth': 6, 'min_samples_split': 0.5075626911486021, 'min_samples_leaf': 0.33640911960077563, 'min_weight_fraction_leaf': 0.1722189640168989, 'max_features': 'sqrt', 'max_leaf_nodes': 3, 'min_impurity_decrease': 0.6458768940600765, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:33:33,960] Trial 28 finished with value: 0.49965 and parameters: {'n_estimators': 172, 'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 0.3925088802214414, 'min_samples_leaf': 0.11284037356601884, 'min_weight_fraction_leaf': 0.07008861852315762, 'max_features': 'auto', 'max_leaf_nodes': 7, 'min_impurity_decrease': 0.7321799801193077, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:33:37,501] Trial 29 finished with value: 0.49965 and parameters: {'n_estimators': 181, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 0.14793917868555362, 'min_samples_leaf': 0.405465799606231, 'min_weight_fraction_leaf': 0.26820732851581214, 'max_features': 'log2', 'max_leaf_nodes': 5, 'min_impurity_decrease': 0.5584143257679843, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:33:40,485] Trial 30 finished with value: 0.49965 and parameters: {'n_estimators': 155, 'criterion': 'entropy', 'max_depth': 11, 'min_samples_split': 0.228966381125303, 'min_samples_leaf': 0.41997864583681627, 'min_weight_fraction_leaf': 0.24118732501544282, 'max_features': 'auto', 'max_leaf_nodes': 8, 'min_impurity_decrease': 0.4655547157257416, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:33:41,251] Trial 31 finished with value: 0.49965 and parameters: {'n_estimators': 31, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 0.16806801877665767, 'min_samples_leaf': 0.3800470586976944, 'min_weight_fraction_leaf': 0.13131025772891683, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 0.181806763877525, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:33:44,316] Trial 32 finished with value: 0.49965 and parameters: {'n_estimators': 160, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 0.30713680811307237, 'min_samples_leaf': 0.43078225655453656, 'min_weight_fraction_leaf': 0.2165039754549523, 'max_features': 'auto', 'max_leaf_nodes': 12, 'min_impurity_decrease': 0.0024824184060687066, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:33:47,125] Trial 33 finished with value: 0.49965 and parameters: {'n_estimators': 144, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 0.1202904670415828, 'min_samples_leaf': 0.3979013755721424, 'min_weight_fraction_leaf': 0.314045615587883, 'max_features': 'auto', 'max_leaf_nodes': 6, 'min_impurity_decrease': 0.32236480735064166, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:33:48,443] Trial 34 finished with value: 0.49965 and parameters: {'n_estimators': 63, 'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 0.11409335724415484, 'min_samples_leaf': 0.36679022116140825, 'min_weight_fraction_leaf': 0.21926927447051217, 'max_features': 'auto', 'max_leaf_nodes': 8, 'min_impurity_decrease': 0.09546201967665204, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:33:50,833] Trial 35 finished with value: 0.49965 and parameters: {'n_estimators': 120, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 0.10619186536655278, 'min_samples_leaf': 0.4162016224570665, 'min_weight_fraction_leaf': 0.36531982298475435, 'max_features': 'sqrt', 'max_leaf_nodes': 12, 'min_impurity_decrease': 0.2599717843366653, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:33:51,902] Trial 36 finished with value: 0.49965 and parameters: {'n_estimators': 46, 'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 0.24783748594133262, 'min_samples_leaf': 0.2750146381926115, 'min_weight_fraction_leaf': 0.24057960659268368, 'max_features': 'auto', 'max_leaf_nodes': 78, 'min_impurity_decrease': 0.09802281725360082, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:33:56,089] Trial 37 finished with value: 0.49965 and parameters: {'n_estimators': 181, 'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 0.41568617465559815, 'min_samples_leaf': 0.311390676302354, 'min_weight_fraction_leaf': 0.11030524975335536, 'max_features': 'sqrt', 'max_leaf_nodes': 2, 'min_impurity_decrease': 0.4024733226193755, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:33:56,739] Trial 38 finished with value: 0.49965 and parameters: {'n_estimators': 23, 'criterion': 'log_loss', 'max_depth': 5, 'min_samples_split': 0.3260817574217848, 'min_samples_leaf': 0.24524211479438585, 'min_weight_fraction_leaf': 0.14909064107106584, 'max_features': 'log2', 'max_leaf_nodes': 19, 'min_impurity_decrease': 0.2204635327417933, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:34:00,776] Trial 39 finished with value: 0.49965 and parameters: {'n_estimators': 199, 'criterion': 'entropy', 'max_depth': 13, 'min_samples_split': 0.25984424057146105, 'min_samples_leaf': 0.34365986758491784, 'min_weight_fraction_leaf': 0.1992328012367001, 'max_features': 'auto', 'max_leaf_nodes': 13, 'min_impurity_decrease': 0.36101143001641617, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:02,409] Trial 40 finished with value: 0.49965 and parameters: {'n_estimators': 75, 'criterion': 'log_loss', 'max_depth': 6, 'min_samples_split': 0.4541044377703619, 'min_samples_leaf': 0.2204709796602206, 'min_weight_fraction_leaf': 0.3616579606237851, 'max_features': 'log2', 'max_leaf_nodes': 35, 'min_impurity_decrease': 0.5876157345783006, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:03,360] Trial 41 finished with value: 0.49965 and parameters: {'n_estimators': 42, 'criterion': 'gini', 'max_depth': 32, 'min_samples_split': 0.3468207680115355, 'min_samples_leaf': 0.46204832673952606, 'min_weight_fraction_leaf': 0.08780467298433224, 'max_features': 'sqrt', 'max_leaf_nodes': 59, 'min_impurity_decrease': 0.7823671832746664, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:04,572] Trial 42 finished with value: 0.49965 and parameters: {'n_estimators': 57, 'criterion': 'gini', 'max_depth': 17, 'min_samples_split': 0.3861536505634058, 'min_samples_leaf': 0.43471460877794843, 'min_weight_fraction_leaf': 0.11376733088124558, 'max_features': 'sqrt', 'max_leaf_nodes': 28, 'min_impurity_decrease': 0.6459284529638146, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:05,470] Trial 43 finished with value: 0.49965 and parameters: {'n_estimators': 37, 'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 0.2134690150103345, 'min_samples_leaf': 0.38534865850525774, 'min_weight_fraction_leaf': 0.025756148131528947, 'max_features': 'sqrt', 'max_leaf_nodes': 45, 'min_impurity_decrease': 0.8098033823138303, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:06,103] Trial 44 finished with value: 0.49965 and parameters: {'n_estimators': 24, 'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 0.4950813004278356, 'min_samples_leaf': 0.3598912111976474, 'min_weight_fraction_leaf': 0.16979256677035443, 'max_features': 'sqrt', 'max_leaf_nodes': 95, 'min_impurity_decrease': 0.5163374352675629, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:08,036] Trial 45 finished with value: 0.49965 and parameters: {'n_estimators': 93, 'criterion': 'gini', 'max_depth': 8, 'min_samples_split': 0.4328193920180629, 'min_samples_leaf': 0.4141936291407341, 'min_weight_fraction_leaf': 0.0858123116882789, 'max_features': 'log2', 'max_leaf_nodes': 127, 'min_impurity_decrease': 0.6898025068831413, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:34:11,166] Trial 46 finished with value: 0.49965 and parameters: {'n_estimators': 165, 'criterion': 'entropy', 'max_depth': 16, 'min_samples_split': 0.2749000283567001, 'min_samples_leaf': 0.4796842957972497, 'min_weight_fraction_leaf': 0.1483199827764075, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 0.5799457659415855, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:11,654] Trial 47 finished with value: 0.49965 and parameters: {'n_estimators': 16, 'criterion': 'log_loss', 'max_depth': 13, 'min_samples_split': 0.32538825919661735, 'min_samples_leaf': 0.3226083123414598, 'min_weight_fraction_leaf': 0.03566514409116929, 'max_features': 'sqrt', 'max_leaf_nodes': 66, 'min_impurity_decrease': 0.6257701492458294, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:13,896] Trial 48 finished with value: 0.49965 and parameters: {'n_estimators': 114, 'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 0.1813659276559747, 'min_samples_leaf': 0.4013185137117174, 'min_weight_fraction_leaf': 0.09661925898082248, 'max_features': 'log2', 'max_leaf_nodes': 44, 'min_impurity_decrease': 0.7447003083049015, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:34:16,582] Trial 49 finished with value: 0.49965 and parameters: {'n_estimators': 135, 'criterion': 'log_loss', 'max_depth': 19, 'min_samples_split': 0.5414217301642893, 'min_samples_leaf': 0.43661699475793947, 'min_weight_fraction_leaf': 0.1594287508435631, 'max_features': 'auto', 'max_leaf_nodes': 16, 'min_impurity_decrease': 0.8492769852310299, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:17,598] Trial 50 finished with value: 0.49965 and parameters: {'n_estimators': 46, 'criterion': 'log_loss', 'max_depth': 3, 'min_samples_split': 0.21477642438010122, 'min_samples_leaf': 0.3717691249412727, 'min_weight_fraction_leaf': 0.11377207193179346, 'max_features': 'log2', 'max_leaf_nodes': 20, 'min_impurity_decrease': 0.6851225050728041, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:34:18,988] Trial 51 finished with value: 0.49965 and parameters: {'n_estimators': 66, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 0.3934310991851116, 'min_samples_leaf': 0.4896315572955359, 'min_weight_fraction_leaf': 0.256805257525653, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 0.43960194982185247, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:34:20,797] Trial 52 finished with value: 0.49965 and parameters: {'n_estimators': 87, 'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 0.3432147940587272, 'min_samples_leaf': 0.4510744122810881, 'min_weight_fraction_leaf': 0.3913846264243035, 'max_features': 'auto', 'max_leaf_nodes': 5, 'min_impurity_decrease': 0.5129234132764, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:34:21,587] Trial 53 finished with value: 0.49965 and parameters: {'n_estimators': 32, 'criterion': 'gini', 'max_depth': 29, 'min_samples_split': 0.27688133128012826, 'min_samples_leaf': 0.468472330645973, 'min_weight_fraction_leaf': 0.2999833876643324, 'max_features': 'auto', 'max_leaf_nodes': 3, 'min_impurity_decrease': 0.36592560737128754, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:34:23,128] Trial 54 finished with value: 0.49965 and parameters: {'n_estimators': 74, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 0.4718242996737997, 'min_samples_leaf': 0.4463370737466665, 'min_weight_fraction_leaf': 0.21345593952638595, 'max_features': 'auto', 'max_leaf_nodes': 10, 'min_impurity_decrease': 0.9172045692836315, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:24,363] Trial 55 finished with value: 0.49965 and parameters: {'n_estimators': 57, 'criterion': 'log_loss', 'max_depth': 7, 'min_samples_split': 0.30574210759139736, 'min_samples_leaf': 0.4210023454990222, 'min_weight_fraction_leaf': 0.1804145755557112, 'max_features': 'sqrt', 'max_leaf_nodes': 9, 'min_impurity_decrease': 0.6107012428710837, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:34:25,356] Trial 56 finished with value: 0.49965 and parameters: {'n_estimators': 40, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 0.2444261762444003, 'min_samples_leaf': 0.3938492939743984, 'min_weight_fraction_leaf': 0.13895774095842917, 'max_features': 'auto', 'max_leaf_nodes': 6, 'min_impurity_decrease': 0.7110573157330944, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:28,345] Trial 57 finished with value: 0.49965 and parameters: {'n_estimators': 145, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 0.36118736348581526, 'min_samples_leaf': 0.21706160189639312, 'min_weight_fraction_leaf': 0.25706550491096647, 'max_features': 'sqrt', 'max_leaf_nodes': 29, 'min_impurity_decrease': 0.6558448955590376, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:32,057] Trial 58 finished with value: 0.49965 and parameters: {'n_estimators': 185, 'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 0.5911187513336746, 'min_samples_leaf': 0.3769984619658239, 'min_weight_fraction_leaf': 0.06929707106230568, 'max_features': 'log2', 'max_leaf_nodes': 7, 'min_impurity_decrease': 0.48600297152348937, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:34:33,111] Trial 59 finished with value: 0.49965 and parameters: {'n_estimators': 47, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 0.4128334067824486, 'min_samples_leaf': 0.3479948496801546, 'min_weight_fraction_leaf': 0.23307605524856367, 'max_features': 'auto', 'max_leaf_nodes': 13, 'min_impurity_decrease': 0.5498184648981524, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:36,400] Trial 60 finished with value: 0.49965 and parameters: {'n_estimators': 171, 'criterion': 'log_loss', 'max_depth': 17, 'min_samples_split': 0.36591755313208957, 'min_samples_leaf': 0.35672794948556874, 'min_weight_fraction_leaf': 0.15985368199493735, 'max_features': 'sqrt', 'max_leaf_nodes': 5, 'min_impurity_decrease': 0.4379001077256073, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:38,684] Trial 61 finished with value: 0.49965 and parameters: {'n_estimators': 102, 'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 0.42454681160195873, 'min_samples_leaf': 0.20141927090104816, 'min_weight_fraction_leaf': 0.1294588941194785, 'max_features': 'log2', 'max_leaf_nodes': 11, 'min_impurity_decrease': 0.7419013128401606, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:40,164] Trial 62 finished with value: 0.49965 and parameters: {'n_estimators': 67, 'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 0.2949412334085857, 'min_samples_leaf': 0.2553503041712669, 'min_weight_fraction_leaf': 0.18853476362032257, 'max_features': 'log2', 'max_leaf_nodes': 17, 'min_impurity_decrease': 0.6243069168757667, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:41,357] Trial 63 finished with value: 0.49965 and parameters: {'n_estimators': 52, 'criterion': 'gini', 'max_depth': 11, 'min_samples_split': 0.4510189739902998, 'min_samples_leaf': 0.14231242043773668, 'min_weight_fraction_leaf': 0.28466519121352746, 'max_features': 'log2', 'max_leaf_nodes': 23, 'min_impurity_decrease': 0.13532398968616238, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:43,106] Trial 64 finished with value: 0.49965 and parameters: {'n_estimators': 80, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 0.40150736232841, 'min_samples_leaf': 0.271914603479496, 'min_weight_fraction_leaf': 0.19451877246759303, 'max_features': 'log2', 'max_leaf_nodes': 9, 'min_impurity_decrease': 0.004962850016291084, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:34:43,849] Trial 65 finished with value: 0.49965 and parameters: {'n_estimators': 29, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 0.14289167011611356, 'min_samples_leaf': 0.1890808639893633, 'min_weight_fraction_leaf': 0.21886588647879962, 'max_features': 'auto', 'max_leaf_nodes': 14, 'min_impurity_decrease': 0.27044819191335623, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:44,438] Trial 66 finished with value: 0.49965 and parameters: {'n_estimators': 19, 'criterion': 'gini', 'max_depth': 8, 'min_samples_split': 0.3267534640529613, 'min_samples_leaf': 0.14738714355702326, 'min_weight_fraction_leaf': 0.17705487838895026, 'max_features': 'log2', 'max_leaf_nodes': 7, 'min_impurity_decrease': 0.33284554142558365, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:34:45,861] Trial 67 finished with value: 0.49965 and parameters: {'n_estimators': 60, 'criterion': 'log_loss', 'max_depth': 2, 'min_samples_split': 0.36553235830507325, 'min_samples_leaf': 0.23140819312356095, 'min_weight_fraction_leaf': 0.26745094429301114, 'max_features': 'auto', 'max_leaf_nodes': 76, 'min_impurity_decrease': 0.5834186509684409, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:48,742] Trial 68 finished with value: 0.49965 and parameters: {'n_estimators': 149, 'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 0.1908907375538756, 'min_samples_leaf': 0.23793570714716603, 'min_weight_fraction_leaf': 0.0011659093715099822, 'max_features': 'sqrt', 'max_leaf_nodes': 56, 'min_impurity_decrease': 0.5274285895528437, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:49,150] Trial 69 finished with value: 0.49965 and parameters: {'n_estimators': 11, 'criterion': 'log_loss', 'max_depth': 14, 'min_samples_split': 0.24906020256291495, 'min_samples_leaf': 0.4064045180555341, 'min_weight_fraction_leaf': 0.23066594488561737, 'max_features': 'log2', 'max_leaf_nodes': 2, 'min_impurity_decrease': 0.042303980634749834, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:34:52,421] Trial 70 finished with value: 0.49965 and parameters: {'n_estimators': 159, 'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 0.23198369735415664, 'min_samples_leaf': 0.10074983195184664, 'min_weight_fraction_leaf': 0.20428993496364684, 'max_features': 'auto', 'max_leaf_nodes': 4, 'min_impurity_decrease': 0.19024357239062972, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:55,278] Trial 71 finished with value: 0.49965 and parameters: {'n_estimators': 135, 'criterion': 'entropy', 'max_depth': 23, 'min_samples_split': 0.43436081997894166, 'min_samples_leaf': 0.25732508053324843, 'min_weight_fraction_leaf': 0.25010572949966287, 'max_features': 'sqrt', 'max_leaf_nodes': 88, 'min_impurity_decrease': 0.13723421289560228, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:34:58,933] Trial 72 finished with value: 0.49965 and parameters: {'n_estimators': 178, 'criterion': 'entropy', 'max_depth': 17, 'min_samples_split': 0.3849040307697923, 'min_samples_leaf': 0.291467348025404, 'min_weight_fraction_leaf': 0.22732957469539658, 'max_features': 'sqrt', 'max_leaf_nodes': 102, 'min_impurity_decrease': 0.3043278122402351, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:35:02,391] Trial 73 finished with value: 0.49965 and parameters: {'n_estimators': 157, 'criterion': 'entropy', 'max_depth': 29, 'min_samples_split': 0.4740150873912463, 'min_samples_leaf': 0.20708918695575235, 'min_weight_fraction_leaf': 0.24380783575244644, 'max_features': 'sqrt', 'max_leaf_nodes': 51, 'min_impurity_decrease': 0.23895045352122002, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:35:05,159] Trial 74 finished with value: 0.49965 and parameters: {'n_estimators': 126, 'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 0.5145043762819451, 'min_samples_leaf': 0.2463736108887002, 'min_weight_fraction_leaf': 0.20888178499609145, 'max_features': 'sqrt', 'max_leaf_nodes': 65, 'min_impurity_decrease': 0.49015792235450273, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:35:08,414] Trial 75 finished with value: 0.49965 and parameters: {'n_estimators': 152, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 0.3432647761764043, 'min_samples_leaf': 0.30647966967622475, 'min_weight_fraction_leaf': 0.19942422475186097, 'max_features': 'sqrt', 'max_leaf_nodes': 35, 'min_impurity_decrease': 0.6718895948029356, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:35:11,670] Trial 76 finished with value: 0.49965 and parameters: {'n_estimators': 166, 'criterion': 'entropy', 'max_depth': 22, 'min_samples_split': 0.2785690746487976, 'min_samples_leaf': 0.27751656666177704, 'min_weight_fraction_leaf': 0.16655223850630443, 'max_features': 'sqrt', 'max_leaf_nodes': 5, 'min_impurity_decrease': 0.07540799975581795, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:35:12,537] Trial 77 finished with value: 0.49965 and parameters: {'n_estimators': 36, 'criterion': 'log_loss', 'max_depth': 20, 'min_samples_split': 0.3086440841621835, 'min_samples_leaf': 0.3315722923047183, 'min_weight_fraction_leaf': 0.15023011124877406, 'max_features': 'auto', 'max_leaf_nodes': 86, 'min_impurity_decrease': 0.5478304835600455, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:35:13,766] Trial 78 finished with value: 0.49965 and parameters: {'n_estimators': 52, 'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 0.38935100498214475, 'min_samples_leaf': 0.22839648842324473, 'min_weight_fraction_leaf': 0.18903569890900085, 'max_features': 'log2', 'max_leaf_nodes': 6, 'min_impurity_decrease': 0.13950877755145702, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:35:14,766] Trial 79 finished with value: 0.49965 and parameters: {'n_estimators': 42, 'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 0.4137680112827161, 'min_samples_leaf': 0.38688623801913363, 'min_weight_fraction_leaf': 0.11141126891664366, 'max_features': 'auto', 'max_leaf_nodes': 113, 'min_impurity_decrease': 0.1736533639691476, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:35:16,316] Trial 80 finished with value: 0.49965 and parameters: {'n_estimators': 69, 'criterion': 'log_loss', 'max_depth': 18, 'min_samples_split': 0.17194178279751648, 'min_samples_leaf': 0.26517262217461607, 'min_weight_fraction_leaf': 0.32969536674884015, 'max_features': 'sqrt', 'max_leaf_nodes': 15, 'min_impurity_decrease': 0.7216136917132483, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:35:18,844] Trial 81 finished with value: 0.49965 and parameters: {'n_estimators': 127, 'criterion': 'log_loss', 'max_depth': 9, 'min_samples_split': 0.20503386749308503, 'min_samples_leaf': 0.24165601949234652, 'min_weight_fraction_leaf': 0.039686249525849815, 'max_features': 'sqrt', 'max_leaf_nodes': 3, 'min_impurity_decrease': 0.40140508145469755, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:35:21,074] Trial 82 finished with value: 0.49965 and parameters: {'n_estimators': 111, 'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 0.13036140822374803, 'min_samples_leaf': 0.42994630287890534, 'min_weight_fraction_leaf': 0.015431037583536311, 'max_features': 'sqrt', 'max_leaf_nodes': 48, 'min_impurity_decrease': 0.2884408405419579, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:35:23,773] Trial 83 finished with value: 0.49965 and parameters: {'n_estimators': 140, 'criterion': 'log_loss', 'max_depth': 7, 'min_samples_split': 0.26311394370392915, 'min_samples_leaf': 0.24862256288848447, 'min_weight_fraction_leaf': 0.0490993279852268, 'max_features': 'sqrt', 'max_leaf_nodes': 39, 'min_impurity_decrease': 0.4583678913971041, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:35:26,999] Trial 84 finished with value: 0.49965 and parameters: {'n_estimators': 162, 'criterion': 'log_loss', 'max_depth': 16, 'min_samples_split': 0.3485855150619266, 'min_samples_leaf': 0.22552698724209808, 'min_weight_fraction_leaf': 0.08599635336258696, 'max_features': 'sqrt', 'max_leaf_nodes': 63, 'min_impurity_decrease': 0.7743916634963459, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:35:30,360] Trial 85 finished with value: 0.49965 and parameters: {'n_estimators': 174, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 0.15595969880964514, 'min_samples_leaf': 0.28447627479924714, 'min_weight_fraction_leaf': 0.07533251411426514, 'max_features': 'auto', 'max_leaf_nodes': 73, 'min_impurity_decrease': 0.573493634365984, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:35:32,276] Trial 86 finished with value: 0.49965 and parameters: {'n_estimators': 89, 'criterion': 'log_loss', 'max_depth': 6, 'min_samples_split': 0.30697548293486027, 'min_samples_leaf': 0.2626116672102698, 'min_weight_fraction_leaf': 0.0985158315819386, 'max_features': 'log2', 'max_leaf_nodes': 56, 'min_impurity_decrease': 0.34633650446098513, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:35:36,691] Trial 87 finished with value: 0.49965 and parameters: {'n_estimators': 188, 'criterion': 'entropy', 'max_depth': 24, 'min_samples_split': 0.10641978731899052, 'min_samples_leaf': 0.2331406361368431, 'min_weight_fraction_leaf': 0.0594141903338818, 'max_features': 'sqrt', 'max_leaf_nodes': 52, 'min_impurity_decrease': 0.38503925310189985, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:35:38,067] Trial 88 finished with value: 0.49965 and parameters: {'n_estimators': 62, 'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 0.2267056006047116, 'min_samples_leaf': 0.21412640924888954, 'min_weight_fraction_leaf': 0.1327240560935928, 'max_features': 'auto', 'max_leaf_nodes': 31, 'min_impurity_decrease': 0.42788635637841255, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:35:40,217] Trial 89 finished with value: 0.49965 and parameters: {'n_estimators': 99, 'criterion': 'log_loss', 'max_depth': 3, 'min_samples_split': 0.37371853245534953, 'min_samples_leaf': 0.19677639576983158, 'min_weight_fraction_leaf': 0.1738930043659333, 'max_features': 'sqrt', 'max_leaf_nodes': 70, 'min_impurity_decrease': 0.3083611762572587, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:35:41,257] Trial 90 finished with value: 0.49965 and parameters: {'n_estimators': 47, 'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 0.1942891704386964, 'min_samples_leaf': 0.30146925985367246, 'min_weight_fraction_leaf': 0.13902409041406266, 'max_features': 'log2', 'max_leaf_nodes': 43, 'min_impurity_decrease': 0.5066925674128544, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:35:42,017] Trial 91 finished with value: 0.49965 and parameters: {'n_estimators': 31, 'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 0.32776542629125716, 'min_samples_leaf': 0.2489255809100429, 'min_weight_fraction_leaf': 0.12340052321397474, 'max_features': 'auto', 'max_leaf_nodes': 62, 'min_impurity_decrease': 0.6469757197651401, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:35:43,635] Trial 92 finished with value: 0.49965 and parameters: {'n_estimators': 79, 'criterion': 'entropy', 'max_depth': 13, 'min_samples_split': 0.5629703277043281, 'min_samples_leaf': 0.22329530661264596, 'min_weight_fraction_leaf': 0.15660171440379939, 'max_features': 'auto', 'max_leaf_nodes': 26, 'min_impurity_decrease': 0.6078593475483344, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:35:44,873] Trial 93 finished with value: 0.49965 and parameters: {'n_estimators': 57, 'criterion': 'entropy', 'max_depth': 22, 'min_samples_split': 0.43793812376821467, 'min_samples_leaf': 0.28224107682478466, 'min_weight_fraction_leaf': 0.22229093553072915, 'max_features': 'auto', 'max_leaf_nodes': 79, 'min_impurity_decrease': 0.7070157214870835, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:35:45,879] Trial 94 finished with value: 0.49965 and parameters: {'n_estimators': 41, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 0.2858601778249793, 'min_samples_leaf': 0.23394395338928067, 'min_weight_fraction_leaf': 0.10162542304507106, 'max_features': 'auto', 'max_leaf_nodes': 48, 'min_impurity_decrease': 0.47287883474828885, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:35:47,077] Trial 95 finished with value: 0.49965 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 0.41092538548414304, 'min_samples_leaf': 0.21384277583984276, 'min_weight_fraction_leaf': 0.1814199961864852, 'max_features': 'auto', 'max_leaf_nodes': 7, 'min_impurity_decrease': 0.6765927740113548, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:35:47,792] Trial 96 finished with value: 0.49965 and parameters: {'n_estimators': 26, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 0.45992308971264956, 'min_samples_leaf': 0.26604208637687504, 'min_weight_fraction_leaf': 0.20956224534072154, 'max_features': 'auto', 'max_leaf_nodes': 8, 'min_impurity_decrease': 0.5945322994102515, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:35:50,649] Trial 97 finished with value: 0.49965 and parameters: {'n_estimators': 150, 'criterion': 'log_loss', 'max_depth': 32, 'min_samples_split': 0.49812999175655337, 'min_samples_leaf': 0.3123747801777487, 'min_weight_fraction_leaf': 0.2373690721894015, 'max_features': 'log2', 'max_leaf_nodes': 59, 'min_impurity_decrease': 0.7562871951640474, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n[I 2023-10-14 16:35:51,537] Trial 98 finished with value: 0.49965 and parameters: {'n_estimators': 35, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 0.2609162085209485, 'min_samples_leaf': 0.25409809317277615, 'min_weight_fraction_leaf': 0.015214961792126926, 'max_features': 'sqrt', 'max_leaf_nodes': 11, 'min_impurity_decrease': 0.6343875625448447, 'bootstrap': True}. Best is trial 0 with value: 0.49965.\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n[I 2023-10-14 16:35:53,938] Trial 99 finished with value: 0.49965 and parameters: {'n_estimators': 119, 'criterion': 'gini', 'max_depth': 8, 'min_samples_split': 0.3789099594329366, 'min_samples_leaf': 0.24012583147486832, 'min_weight_fraction_leaf': 0.16817846923807292, 'max_features': 'auto', 'max_leaf_nodes': 31, 'min_impurity_decrease': 0.698329823239304, 'bootstrap': False}. Best is trial 0 with value: 0.49965.\n","output_type":"stream"},{"name":"stdout","text":"Number of finished trials: 100\nBest trial: {'n_estimators': 158, 'criterion': 'log_loss', 'max_depth': 17, 'min_samples_split': 0.3880243171996576, 'min_samples_leaf': 0.4247838122008928, 'min_weight_fraction_leaf': 0.170287707952885, 'max_features': 'log2', 'max_leaf_nodes': 7, 'min_impurity_decrease': 0.6467542020296969, 'bootstrap': True}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check the dimensions and the type of the feature matrix\nprint(X.shape, type(X))","metadata":{"execution":{"iopub.status.busy":"2023-10-14T16:35:53.959802Z","iopub.execute_input":"2023-10-14T16:35:53.960771Z","iopub.status.idle":"2023-10-14T16:35:53.966652Z","shell.execute_reply.started":"2023-10-14T16:35:53.960735Z","shell.execute_reply":"2023-10-14T16:35:53.965526Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"(100000, 1048576) <class 'scipy.sparse.csr.csr_matrix'>\n","output_type":"stream"}]},{"cell_type":"code","source":"# Assumez que best_params est le dictionnaire des meilleurs paramètres retournés par Optuna\nbest_params = study.best_trial.params\n\n# Créez un nouveau classificateur Random Forest avec ces paramètres\nfinal_classifier = RandomForestClassifier(**best_params, random_state=50, verbose=1)\n\n# Entraînez le classificateur sur l'ensemble d'entraînement\nfinal_classifier.fit(X_train, y_train)\n\n# Faites des prédictions sur l'ensemble de test\nfinal_predictions = final_classifier.predict(X_test)\n\n# Évaluez la performance du classificateur\nfinal_accuracy = accuracy_score(y_test, final_predictions)\nconf_matrix = confusion_matrix(y_test, final_predictions)\nclass_report = classification_report(y_test, final_predictions)\n\n# Print les métriques d'évaluation\nprint(f'Final Accuracy: {final_accuracy}')\nprint(f'Confusion Matrix:\\n{conf_matrix}')\nprint(f'Classification Report:\\n{class_report}')","metadata":{"execution":{"iopub.status.busy":"2023-10-14T16:35:53.968187Z","iopub.execute_input":"2023-10-14T16:35:53.968849Z","iopub.status.idle":"2023-10-14T16:35:57.028483Z","shell.execute_reply.started":"2023-10-14T16:35:53.968813Z","shell.execute_reply":"2023-10-14T16:35:57.027503Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.4s\n[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.5s\n","output_type":"stream"},{"name":"stdout","text":"Final Accuracy: 0.49965\nConfusion Matrix:\n[[ 9993     0]\n [10007     0]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.50      1.00      0.67      9993\n           1       0.00      0.00      0.00     10007\n\n    accuracy                           0.50     20000\n   macro avg       0.25      0.50      0.33     20000\nweighted avg       0.25      0.50      0.33     20000\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Multi Layer Perceptron (MLP)\nMulti Layer Perceptron (MLP) is a class of feedforward artificial neural network. By flattening the DNA sequences and employing a suitable encoding scheme, MLPs can be trained to differentiate between human and gorilla DNA based on the input features.","metadata":{}},{"cell_type":"code","source":"# Placeholder for MLP model code","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n---","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nimport numpy as np\n\nfrom transformers import BertTokenizer, TFBertForSequenceClassification\nfrom transformers import TrainingArguments, Trainer\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n# Load dataset\ndata = pd.read_csv('../input/ml-olympiad-gdscuiz-and-tfugagadir/train.csv',usecols=['genome_sequence','species'])\ndata = data.sample(n=10000)\nsequences = data['genome_sequence'].tolist()\nlabels = data['species'].tolist()\n\n# Tokenization\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ninputs = tokenizer(sequences, truncation=True, padding=True, return_tensors='tf')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-13T17:17:01.162546Z","iopub.execute_input":"2023-10-13T17:17:01.162981Z","iopub.status.idle":"2023-10-13T17:17:01.172362Z","shell.execute_reply.started":"2023-10-13T17:17:01.162948Z","shell.execute_reply":"2023-10-13T17:17:01.169570Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Encode labels\nlabel_encoder = LabelEncoder()\nencoded_labels = label_encoder.fit_transform(labels)\n\n# Convert input_ids to numpy array before splitting\ninput_ids_np = inputs['input_ids'].numpy()\n\n# Split data\ntrain_input_ids, val_input_ids, train_labels, val_labels = train_test_split(input_ids_np, encoded_labels, test_size=0.2)\n\n# If you need to convert them back to tensors for training:\ntrain_input_ids = tf.convert_to_tensor(train_input_ids)\nval_input_ids = tf.convert_to_tensor(val_input_ids)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:29:36.839706Z","iopub.execute_input":"2023-10-13T17:29:36.840079Z","iopub.status.idle":"2023-10-13T17:29:36.855335Z","shell.execute_reply.started":"2023-10-13T17:29:36.840045Z","shell.execute_reply":"2023-10-13T17:29:36.854337Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Load pre-trained model and modify\nmodel = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n\n# Training arguments and training\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    evaluation_strategy=\"steps\",\n    eval_steps=50,\n    learning_rate=2e-5,\n)\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\n\n# Define loss and optimizer\nloss = SparseCategoricalCrossentropy(from_logits=True)\noptimizer = Adam()\n\nmodel.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n\n# Convert labels to tensors\ntrain_labels_tensor = tf.convert_to_tensor(train_labels)\nval_labels_tensor = tf.convert_to_tensor(val_labels)\n\n# Train the model\nmodel.fit(train_input_ids, train_labels_tensor, validation_data=(val_input_ids, val_labels_tensor), epochs=3, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:32:00.808498Z","iopub.execute_input":"2023-10-13T17:32:00.808904Z","iopub.status.idle":"2023-10-13T17:36:16.719843Z","shell.execute_reply.started":"2023-10-13T17:32:00.808873Z","shell.execute_reply":"2023-10-13T17:36:16.718830Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n\nSome weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n1000/1000 [==============================] - 117s 72ms/step - loss: 0.7013 - accuracy: 0.4992 - val_loss: 0.6950 - val_accuracy: 0.4965\nEpoch 2/3\n1000/1000 [==============================] - 68s 68ms/step - loss: 0.7008 - accuracy: 0.4976 - val_loss: 0.6977 - val_accuracy: 0.4965\nEpoch 3/3\n1000/1000 [==============================] - 69s 69ms/step - loss: 0.6992 - accuracy: 0.4976 - val_loss: 0.6941 - val_accuracy: 0.4965\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fb44a64b610>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import accuracy_score\n\n# Load the test dataset\ntest_data = pd.read_csv('test.csv')\ntest_sequences = test_data['genome_sequence'].tolist()\n\n# Tokenize the sequences\ntest_inputs = tokenizer(test_sequences, truncation=True, padding=True, return_tensors='tf')\n\n# Predict using the fine-tuned model\npredictions = model(test_inputs).logits\npredicted_labels = predictions.argmax(axis=1)\n\n# Convert species names in the test set to numerical labels\ntrue_labels = label_encoder.transform(test_data['species'].tolist())\n\n# Calculate accuracy\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:18:11.235231Z","iopub.status.idle":"2023-10-13T17:18:11.236047Z","shell.execute_reply.started":"2023-10-13T17:18:11.235783Z","shell.execute_reply":"2023-10-13T17:18:11.235805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the data\ntrain_data = pd.read_csv('../input/ml-olympiad-gdscuiz-and-tfugagadir/train.csv',usecols=['genome_sequence','species'])\ntrain_data = train_data.sample(n=500000)\nspecies_counts = train_data['species'].value_counts(normalize=True)\nprint(species_counts)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:17:07.717595Z","iopub.status.idle":"2023-10-13T17:17:07.718380Z","shell.execute_reply.started":"2023-10-13T17:17:07.718110Z","shell.execute_reply":"2023-10-13T17:17:07.718132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build the model\nimport tensorflow as tf\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu',\n                           input_shape=(9, 9, 4),\n                           padding='same',\n                           kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', \n                           padding='same',\n                           kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n    tf.keras.layers.Dropout(0.2),\n\n    tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu', \n                           padding='same',\n                           kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n    tf.keras.layers.Dropout(0.2),\n\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(2, activation='softmax')  # Assuming 2 classes, adjust if necessary\n])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:17:07.719802Z","iopub.status.idle":"2023-10-13T17:17:07.720596Z","shell.execute_reply.started":"2023-10-13T17:17:07.720366Z","shell.execute_reply":"2023-10-13T17:17:07.720387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_dataset(data, test=False):\n    def one_hot_encode(sequence):\n        mapping = {'a': [1, 0, 0, 0], 'c': [0, 1, 0, 0], 'g': [0, 0, 1, 0], 't': [0, 0, 0, 1]}\n        return [mapping[char] for char in sequence]\n\n    encoded_seqs = data['genome_sequence'].apply(one_hot_encode)\n    padded_seqs = tf.keras.preprocessing.sequence.pad_sequences(encoded_seqs, padding='post')\n    \n    if not test:\n        # Encode the species labels into numerical values\n        label_encoder = LabelEncoder()\n        encoded_labels = label_encoder.fit_transform(data['species'])\n        encoded_labels = tf.keras.utils.to_categorical(encoded_labels, num_classes=2)\n    \n    num_samples = len(padded_seqs)\n    reshaped_data = np.zeros((num_samples, 9, 9, 4))  # Initialize an empty array of the desired shape\n\n    for i, sequence in enumerate(padded_seqs):\n        # Reshape the sequence to a 2D 80x4 matrix\n        sequence_2d = sequence.reshape(-1, 4)\n\n        # Pad this matrix with a row of zeros to get a 81x4 matrix\n        padded_sequence = np.vstack((sequence_2d, np.zeros((1, 4))))\n\n        # Reshape this matrix to a 9x9x4 tensor\n        reshaped_sequence = padded_sequence.reshape(9, 9, 4)\n\n        # Store the reshaped sequence in the reshaped_data array\n        reshaped_data[i] = reshaped_sequence\n    if not test:\n        return reshaped_data, encoded_labels\n    else:\n        return reshaped_data","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:17:07.721966Z","iopub.status.idle":"2023-10-13T17:17:07.722813Z","shell.execute_reply.started":"2023-10-13T17:17:07.722570Z","shell.execute_reply":"2023-10-13T17:17:07.722594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_data, y_train_data = preprocess_dataset(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:17:07.724067Z","iopub.status.idle":"2023-10-13T17:17:07.725005Z","shell.execute_reply.started":"2023-10-13T17:17:07.724764Z","shell.execute_reply":"2023-10-13T17:17:07.724786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and testing sets\nx_train, x_test, y_train, y_test = train_test_split(x_train_data, y_train_data, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:17:07.726351Z","iopub.status.idle":"2023-10-13T17:17:07.727097Z","shell.execute_reply.started":"2023-10-13T17:17:07.726866Z","shell.execute_reply":"2023-10-13T17:17:07.726887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_images(data_piece):\n    fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n    \n    # Assuming data_piece has shape (9, 9, 4)\n    for i in range(4):\n        img = data_piece[:, :, i]\n        axs[i].imshow(img, cmap='gray')  # or choose a different colormap if preferred\n        axs[i].axis('off')  # to remove the axes for clarity\n        axs[i].set_title(f'Channel {i+1}')\n    \n    plt.show()\nplot_images(x_train[0])","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:17:07.728430Z","iopub.status.idle":"2023-10-13T17:17:07.729188Z","shell.execute_reply.started":"2023-10-13T17:17:07.728947Z","shell.execute_reply":"2023-10-13T17:17:07.728968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\n# Define the Early Stopping and Reduce LR On Plateau callbacks\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:17:07.730597Z","iopub.status.idle":"2023-10-13T17:17:07.731296Z","shell.execute_reply.started":"2023-10-13T17:17:07.731080Z","shell.execute_reply":"2023-10-13T17:17:07.731100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model with the callbacks\nhistory = model.fit(x_train, y_train,\n                    validation_data=(x_test, y_test),\n                    epochs=25,\n                    batch_size=128,\n                    callbacks=[early_stopping, reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:17:07.732600Z","iopub.status.idle":"2023-10-13T17:17:07.733320Z","shell.execute_reply.started":"2023-10-13T17:17:07.733093Z","shell.execute_reply":"2023-10-13T17:17:07.733114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the training and validation accuracy\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\n\n# Plotting the training and validation loss\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:17:07.734754Z","iopub.status.idle":"2023-10-13T17:17:07.735511Z","shell.execute_reply.started":"2023-10-13T17:17:07.735273Z","shell.execute_reply":"2023-10-13T17:17:07.735294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv('../input/ml-olympiad-gdscuiz-and-tfugagadir/test.csv', usecols=['genome_sequence'])\n\nx_test_data = preprocess_dataset(test_data, True)\n\n# Make predictions\npredictions = model.predict(x_test_data)\npredicted_labels = np.argmax(predictions, axis=1)  # assuming a multi-class classification problem\ndi = {\n    0: \"Homo_sapiens\",\n    1: \"Gorilla_gorilla\"\n}\npredicted_labels = [v for v in predicted_labels]","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:17:07.736800Z","iopub.status.idle":"2023-10-13T17:17:07.737535Z","shell.execute_reply.started":"2023-10-13T17:17:07.737308Z","shell.execute_reply":"2023-10-13T17:17:07.737340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(predicted_labels, return_counts=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:17:07.738988Z","iopub.status.idle":"2023-10-13T17:17:07.739771Z","shell.execute_reply.started":"2023-10-13T17:17:07.739537Z","shell.execute_reply":"2023-10-13T17:17:07.739559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create submission DataFrame\nsubmission_df = pd.DataFrame({'id': test_data.index, 'species': predicted_labels})\n\n# Save to CSV\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-13T17:17:07.741174Z","iopub.status.idle":"2023-10-13T17:17:07.741927Z","shell.execute_reply.started":"2023-10-13T17:17:07.741698Z","shell.execute_reply":"2023-10-13T17:17:07.741721Z"},"trusted":true},"execution_count":null,"outputs":[]}]}